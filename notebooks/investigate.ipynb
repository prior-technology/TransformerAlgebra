{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "012a4786",
   "metadata": {},
   "source": [
    "# Investigation of single token prediction in Pythia 160m\n",
    "\n",
    "Investigating how the Pythia 160m model represents knowledge from pre-training, using a prompt intended to generate a token for Dublin as the capital of Ireland. This is the smallest model which behaves like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e599441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies and set up the package\n",
    "# %pip install transformers torch matplotlib\n",
    "\n",
    "# Install the local package in development mode\n",
    "import sys\n",
    "sys.path.insert(0, '../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdb2eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: EleutherAI/pythia-160m-deduped\n",
      "Layers: 12\n",
      "Heads: 12\n",
      "d_model: 768\n"
     ]
    }
   ],
   "source": [
    "from transformer_algebra import PromptedTransformer, load_pythia_model\n",
    "\n",
    "# Load Pythia-160m-deduped from HuggingFace\n",
    "model, tokenizer = load_pythia_model(\"EleutherAI/pythia-160m-deduped\")\n",
    "print(f\"Model: {model.config.name_or_path}\")\n",
    "print(f\"Layers: {model.config.num_hidden_layers}\")\n",
    "print(f\"Heads: {model.config.num_attention_heads}\")\n",
    "print(f\"d_model: {model.config.hidden_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c956c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformer_algebra.core.PromptedTransformer at 0x24aa5dc2700>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = PromptedTransformer(model, tokenizer, \"The capital of Ireland\")\n",
    "#returns an object representing a transformer and a prompt as an operator which acts on a residual vector\n",
    "T\n",
    "# T displays as something like T(<4 tokens>)\n",
    "# or long term maybe $$T(\\underline{The} \\ \\underline{ capital} \\ \\underline{ of} \\ \\underline{ Ireland})$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "703e38c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'PromptedTransformer' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mT\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m is\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#returns an object which represents the result vector from applying the model to the token for \" is\".\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#x\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# x displays as something like T(\\underline(is))\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'PromptedTransformer' object is not callable"
     ]
    }
   ],
   "source": [
    "x = T(\" is\")\n",
    "#returns an object which represents the result vector from applying the model to the token for \" is\".\n",
    "#x\n",
    "# x displays as something like T(\\underline(is))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0bdfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict(x)\n",
    "# Should return an object representing a mapping from tokens to probabilities\n",
    "#logits(x) \n",
    "# Should return an object representing a mapping from tokens to logits\n",
    "#summarise(logits(x)) - outputs as below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d89ae77",
   "metadata": {},
   "source": [
    "Expected result: Top 5 predictions after final layer:\n",
    "  1. ' the' (logit: 786.61)\n",
    "  2. ' a' (logit: 784.93)\n",
    "  3. ' Belfast' (logit: 784.57)\n",
    "  4. ' Dublin' (logit: 784.47)\n",
    "  5. ' now' (logit: 784.44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beea907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand(x)\n",
    "# Should return an object representing the decomposition of the residual stream at x into contributions from each layer\n",
    "#Something like:\n",
    "# LN( \\underline{ is} + \\T_0 \\underline{ is} +  \\T_1  \\underline{ is} ... )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c5fca9",
   "metadata": {},
   "source": [
    "The next step depends on a relation:\n",
    "$$\n",
    "<x, LN(a + b)> = \\frac{<x,a>+<x,b>}{\\left \\| a+b \\right \\|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b04f1671",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logits(x)[\"Dublin\"]\n",
    "# Should return something like\n",
    "# < \\overline{Dublin}, T(\\underline{ is}) > = 783.45\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c6b7077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand(logits(x)[\"Dublin\"])\n",
    "# Should return something like\n",
    "# scale * ( < \\overline{Dublin}, T_0(\\underline{ is} > + < \\overline{Dublin}, T_1(\\underline{ is} > + ... ) = 783.45\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c869cad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
